#!/usr/bin/env python3
"""
æœ€ç»ˆå±•ç¤ºå¯è§†åŒ–è„šæœ¬ - ç”Ÿæˆé¢„æµ‹ä¸çœŸå®å€¼çš„å¯¹æ¯”å›¾
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

import torch
import numpy as np
import nibabel as nib
import os
import matplotlib.pyplot as plt
from nilearn import plotting, datasets, image
import warnings
from utils.paths import get_config_path, get_checkpoint_dir, get_template_dir, resolve_path

# å¿½ç•¥ nilearn çš„ä¸€äº› warning ä»¥ä¿æŒæ¸…çˆ½
warnings.filterwarnings("ignore")

# --- é…ç½®åŒº - ä½¿ç”¨ç»Ÿä¸€çš„è·¯å¾„å·¥å…· ---
MODEL_PATH = get_checkpoint_dir() / "model_ep50.pth"
TEMPLATE_DIR = get_template_dir()
OUTPUT_DIR = resolve_path("./results/final_showcase")

os.makedirs(OUTPUT_DIR, exist_ok=True)

def vector_to_nifti(weights, ica_basis, mask_bool, affine=np.eye(4)):
    """å°† 64ç»´æƒé‡ -> 3D NIfTI å›¾åƒ"""
    # 1. é€†æŠ•å½±: [1, 64] @ [64, Voxels] -> [1, Voxels]
    # è½¬æ¢ä¸º torch.Tensor å¹¶ç¡®ä¿åœ¨åŒä¸€è®¾å¤‡ä¸Š
    if isinstance(weights, np.ndarray):
        weights = torch.from_numpy(weights)
    elif isinstance(weights, torch.Tensor):
        weights = weights.detach()
    
    if isinstance(ica_basis, np.ndarray):
        ica_basis = torch.from_numpy(ica_basis)
    
    # ç¡®ä¿ weights å’Œ ica_basis åœ¨åŒä¸€è®¾å¤‡ä¸Šè¿›è¡ŒçŸ©é˜µä¹˜æ³•
    if isinstance(ica_basis, torch.Tensor):
        ica_basis = ica_basis.to(weights.device)
    
    # æ‰§è¡ŒçŸ©é˜µä¹˜æ³•ï¼ˆåœ¨åŒä¸€è®¾å¤‡ä¸Šï¼‰
    activation_vec_tensor = torch.matmul(weights, ica_basis)
    # ç§»å› CPU å¹¶è½¬æ¢ä¸º numpy
    activation_vec = activation_vec_tensor.cpu().numpy().flatten()
    
    # 2. å¡«å…¥ 3D ç©ºé—´
    vol_data = np.zeros(mask_bool.shape)
    vol_data[mask_bool] = activation_vec
    
    # 3. è½¬ç½®é€‚é… NIfTI (é€šå¸¸ D,H,W -> X,Y,Z å¯èƒ½ä¼šæœ‰è½´å˜æ¢ï¼Œè§† nilearn ä¹ æƒ¯)
    # æˆ‘ä»¬ä¹‹å‰çš„è„šæœ¬æ˜¯æŠŠ depth æ”¾ç¬¬ä¸€ä½çš„ [30, 64, 64]ï¼ŒNifti ä¹ æƒ¯ [64, 64, 30]
    vol_nii_data = np.transpose(vol_data, (2, 1, 0)) 
    
    return nib.Nifti1Image(vol_nii_data, affine)

def main():
    print(f"ğŸŒŸ Starting Final Showcase Generation...")
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # 1. åŠ è½½ç»„ä»¶ - å°è¯•å¤šç§å¯èƒ½çš„æ–‡ä»¶å
    template_dir = TEMPLATE_DIR
    
    # å°è¯•æ‰¾åˆ° ICA åŸºåº•æ–‡ä»¶
    ica_candidates = [
        template_dir / "ica_mixing_matrix.pt",
        template_dir / "ica_basis.pt"
    ]
    
    # å°è¯•æ‰¾åˆ° Mask æ–‡ä»¶
    mask_candidates = [
        template_dir / "mask_dhw.pt",
        template_dir / "gray_mask.pt"
    ]
    
    ICA_PATH = None
    for candidate in ica_candidates:
        if candidate.exists():
            ICA_PATH = candidate
            break
    
    MASK_PATH = None
    for candidate in mask_candidates:
        if candidate.exists():
            MASK_PATH = candidate
            break
    
    if ICA_PATH is None or MASK_PATH is None:
        print("âŒ Error: æ‰¾ä¸åˆ°åŸºåº•æ–‡ä»¶ã€‚")
        print(f"   æ¨¡æ¿ç›®å½•: {template_dir}")
        print(f"   éœ€è¦çš„æ–‡ä»¶:")
        print(f"     - ICAåŸºåº•: ica_mixing_matrix.pt æˆ– ica_basis.pt")
        print(f"     - Mask: mask_dhw.pt æˆ– gray_mask.pt")
        print(f"   è¯·è¿è¡Œé¢„å¤„ç†è„šæœ¬:")
        print(f"     - python processing/run_ica.py")
        print(f"     - æˆ– python processing/rebuild_h5.py")
        return
    
    try:
        basis = torch.load(ICA_PATH, map_location=device, weights_only=False)
        mask_tensor = torch.load(MASK_PATH, map_location='cpu', weights_only=False)
        
        # å¤„ç†ä¸åŒçš„ mask æ ¼å¼
        if mask_tensor.dim() == 3:
            mask = mask_tensor.numpy().astype(bool)
        elif mask_tensor.dim() == 4:
            mask = mask_tensor.squeeze().numpy().astype(bool)
        else:
            mask = mask_tensor.numpy().astype(bool)
            
        print(f"âœ… Loaded ICA basis: {basis.shape}")
        print(f"âœ… Loaded mask: {mask.shape}, {mask.sum()} voxels")
    except Exception as e:
        print(f"âŒ Error loading template files: {e}")
        import traceback
        traceback.print_exc()
        return

    # 2. å‡†å¤‡æ ‡å‡†è§£å‰–åº•å›¾ (MNI Template)
    # è‡ªåŠ¨ä¸‹è½½ MNI152 æ ‡å‡†è„‘ï¼Œä»¥æ­¤ä½œä¸ºèƒŒæ™¯ï¼Œæ˜¾å¾—ä¸“ä¸š
    print("Fetching MNI Template for background...")
    mni_template = datasets.load_mni152_template()

    # 3. åŠ è½½æ¨¡å‹
    from models.classifier_net import PhysicsE2fNet
    import yaml
    
    # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°
    config_path = get_config_path()
    with open(config_path, 'r', encoding='utf-8') as f:
        cfg = yaml.safe_load(f)
    
    # å…ˆè·å–ä¸€æ¡æ•°æ®æ¥ç¡®å®šç»´åº¦
    from data.loaders import FMRIEEGDataset
    ds = FMRIEEGDataset(config_path=str(config_path), lazy_load=False)
    sample_eeg, _ = ds[0]
    eeg_c, eeg_f, eeg_t = sample_eeg.shape
    
    model = PhysicsE2fNet(
        n_ica_components=cfg['data_specs']['n_ica_components'],
        eeg_channels=eeg_c,
        eeg_time_len=eeg_t,
        basis_path=str(ICA_PATH) if ICA_PATH.exists() else None,
        task='regression'
    ).to(device)
    
    # åŠ è½½æƒé‡
    if MODEL_PATH.exists():
        state_dict = torch.load(MODEL_PATH, map_location=device, weights_only=False)
        model.load_state_dict(state_dict)
        print(f"âœ… Model loaded from: {MODEL_PATH}")
    else:
        print(f"âš ï¸  Warning: Model file not found at {MODEL_PATH}")
        print("   Using untrained model for demonstration.")
    model.eval()
    print("âœ… Model loaded successfully.")

    # 4. è·å–æ•°æ®ï¼ˆå·²åœ¨ä¸Šé¢åŠ è½½ï¼‰
    
    # 5. å¼€å§‹ç”Ÿæˆå¯¹æ¯”å›¾
    # éšæœºå– 3 ä¸ªæ ·æœ¬å±•ç¤º
    indices_to_show = [0, 50, 100] # å¯ä»¥æ”¹éšæœº
    indices_to_show = [i for i in indices_to_show if i < len(ds)]
    
    print(f"Generating visualizations for samples: {indices_to_show}")
    
    for idx in indices_to_show:
        eeg, gt_weights = ds[idx]
        
        # é¢„æµ‹
        eeg_input = eeg.unsqueeze(0).to(device).float()
        with torch.no_grad():
            pred_weights = model(eeg_input) # [1, 64]
            
        # --- ç”Ÿæˆ 3D å›¾åƒ ---
        img_pred = vector_to_nifti(pred_weights, basis, mask)
        img_gt = vector_to_nifti(gt_weights.unsqueeze(0), basis, mask)
        
        # ç”±äºæˆ‘ä»¬ç”¨çš„åæ ‡ç³»æ˜¯ Fake Affineï¼Œä¸ºäº†å åŠ åˆ° MNI ä¸Šï¼Œéœ€è¦ Resample
        # è¿™æ­¥æ˜¯å…³é”®ï¼šæŠŠæˆ‘ä»¬çš„ [64,64,30] å¼ºè¡Œæ’å€¼å¯¹é½åˆ° [91,109,91] çš„ MNI
        # è¿™æ ·çœ‹èµ·æ¥æ‰æ˜¯åœ¨â€œçœŸæ­£çš„å¤§è„‘â€ä¸Š
        img_pred_resampled = image.resample_to_img(img_pred, mni_template)
        img_gt_resampled = image.resample_to_img(img_gt, mni_template)
        
        # --- ç»˜å›¾ ---
        fig, axes = plt.subplots(2, 1, figsize=(10, 8))
        
        # ä¸ºäº†ç¾è§‚ï¼Œè®¾ç½®é˜ˆå€¼ï¼ŒæŠŠé‚£ç§æ¥è¿‘0çš„èƒŒæ™¯åº•å™ªåˆ‡æ‰
        # ä½ çš„ loss å¾ˆå¤§ï¼Œè¯´æ˜æ•°å€¼å¾ˆå¤§ (æ¯”å¦‚ +-100)ï¼Œé‚£é˜ˆå€¼å¯ä»¥è®¾ä¸º max çš„ 20%
        display_threshold = np.max(np.abs(pred_weights.cpu().numpy())) * 0.2
        
        # Plot 1: Prediction
        plotting.plot_stat_map(
            img_pred_resampled, bg_img=mni_template, 
            display_mode='z', cut_coords=5, # Zè½´åˆ‡5å¼ 
            threshold=display_threshold,
            title=f"Sample {idx} - EEG Prediction",
            axes=axes[0], colorbar=True
        )
        
        # Plot 2: Ground Truth
        plotting.plot_stat_map(
            img_gt_resampled, bg_img=mni_template, 
            display_mode='z', cut_coords=5, 
            threshold=display_threshold, # ä¿æŒé˜ˆå€¼ä¸€è‡´ä»¥ä¾¿å¯¹æ¯”
            title=f"Sample {idx} - Ground Truth (fMRI)",
            axes=axes[1], colorbar=True
        )
        
        save_p = str(OUTPUT_DIR / f"comparison_sample_{idx}.png")
        plt.savefig(save_p)
        plt.close()
        print(f"   Saved comparison: {save_p}")

    print("\nğŸ‰ Done! è¯·æ‰“å¼€ results/final_showcase æ–‡ä»¶å¤¹æŸ¥çœ‹æœ€ç»ˆæˆæœï¼")

if __name__ == "__main__":
    main()